"""
Agent implementation using LangGraph with Gemini.
This handles the intermediate persona's agentic retrieval capabilities.
"""

import os
import json
import time
from typing import Dict, List, Any, Optional, Tuple, Set
import re
import logging
from pydantic import BaseModel, Field
from tools import WebSearchTool
import google.generativeai as genai
import config
from langgraph.graph import END, StateGraph

# Try different import paths for ToolExecutor based on langgraph version
try:
    from langgraph.prebuilt import ToolExecutor
except ImportError:
    try:
        from langgraph.utils import ToolExecutor
    except ImportError:
        # Create a simple fallback implementation if neither import works
        class ToolExecutor:
            def __init__(self, tools):
                self.tools = {tool.name: tool for tool in tools}
            
            def invoke(self, tool_name, tool_input):
                if tool_name in self.tools:
                    return self.tools[tool_name](tool_input)
                raise ValueError(f"Tool {tool_name} not found")



# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Initialize Gemini
if not hasattr(config, 'GENAI_API_KEY') or not config.GENAI_API_KEY:
    logger.warning("No Gemini API key found in config. Set config.GENAI_API_KEY before using the agent.")
    GEMINI_INITIALIZED = False
else:
    genai.configure(api_key=config.GENAI_API_KEY)
    MODEL_NAME = getattr(config, 'GENAI_MODEL', "gemini-1.5-pro")
    _GEMINI = genai.GenerativeModel(MODEL_NAME)
    GEMINI_INITIALIZED = True

# Define the agent state
class AgentState(BaseModel):
    """State for the agent graph."""
    question: str = Field(description="The user's original question")
    context: List[Dict[str, Any]] = Field(description="The retrieved document chunks")
    answer: str = Field(default="", description="The current answer being built")
    search_results: Dict[str, Any] = Field(default_factory=dict, description="Results from web searches")
    generated_images: List[Dict[str, Any]] = Field(default_factory=list, description="Visualizations generated by the agent")
    tools_used: Set[str] = Field(default_factory=set, description="Tools that have been used")
    thought_process: List[str] = Field(default_factory=list, description="Agent's thought process")
    final_response: Dict[str, Any] = Field(default_factory=dict, description="The final response to return to the user")
    done: bool = Field(default=False, description="Whether the agent has completed its task")

# Initialize tools
web_search_tool = WebSearchTool()
tools = [web_search_tool]

# Create a tool executor
tool_executor = ToolExecutor(tools)

def format_context_for_llm(context_chunks: List[Dict[str, Any]]) -> str:
    """Format the context chunks for the LLM."""
    context_text = []
    
    for chunk in context_chunks:
        page = chunk.get("page", "unknown")
        chunk_type = chunk.get("type", "text")
        content = chunk.get("content", "")
        
        # Format differently based on chunk type
        if chunk_type == "text":
            context_text.append(f"[Page {page}] TEXT: {content}")
        elif chunk_type in ["image", "diagram", "figure"]:
            context_text.append(f"[Page {page}] {chunk_type.upper()}: {content}")
        elif chunk_type == "table":
            context_text.append(f"[Page {page}] TABLE: {content}")
    
    return "\n\n".join(context_text)

def plan_step(state: AgentState) -> AgentState:
    """
    Plan what to do next based on the current state.
    This step decides whether to use tools or generate the final answer.
    """
    # Extract key components
    question = state.question
    context = state.context
    formatted_context = format_context_for_llm(context)
    
    # Create a chain-of-thought prompt for planning
    prompt = f"""You are an AI assistant helping users understand complex document information.
    Your task is to analyze the question and context, then decide what steps to take next.

    QUESTION: {question}

    DOCUMENT CONTEXT:
    {formatted_context}

    Please think step by step:
    1. What is the user asking for?
    2. What key concepts or terms in the context might need explanation for an intermediate user?
    3. Would any diagrams or visualizations help explain the answer?
    4. Do I need to search for additional explanations of technical terms?

    Based on your analysis, decide your next action:
    - If you need to search for explanations of technical terms, use the web_search tool
    - If you need to create a visualization, use the image_generation tool
    - If you have all the information needed, proceed to generate the final answer

    YOUR DETAILED THINKING:
    """

    # Get response from Gemini
    try:
        if not GEMINI_INITIALIZED:
            # Fallback if Gemini isn't initialized
            state.thought_process.append("Gemini not initialized. Proceeding to final answer.")
            state.tools_used.add("final_answer")
            return state
            
        response = _GEMINI.generate_content(prompt)
        
        # Check if response is None or doesn't have text attribute
        if response is None or not hasattr(response, 'text') or response.text is None:
            logger.warning("Received empty response from Gemini API")
            state.thought_process.append("Could not analyze context. Proceeding to final answer.")
            state.tools_used.add("final_answer")
            return state
            
        thinking = response.text.strip()
        
        # Store the thinking process
        state.thought_process.append(thinking)
        
        # Check if tools should be used
        if "web_search" in thinking.lower() and "web_search" not in state.tools_used:
            # Extract terms to search for
            search_terms = extract_search_terms(thinking, question)
            if search_terms:
                state.tools_used.add("web_search")
                return state
        
        
        # If no tools needed or all tools already used, move to answer generation
        state.tools_used.add("final_answer")
        
    except Exception as e:
        logger.exception(f"Error in planning step: {e}")
        state.tools_used.add("final_answer")  # Default to final answer on error
    
    return state

def extract_search_terms(thinking: str, question: str) -> List[str]:
    """Extract technical terms to search for from the thinking process and context."""
    # Common technical term patterns
    technical_patterns = [
        r'\b([A-Z][A-Za-z0-9]+(?:[A-Z][a-z0-9]+)+)\b',  # CamelCase technical terms
        r'\b([a-z]+[-_][a-z]+(?:[-_][a-z]+)*)\b',  # kebab-case or snake_case terms
        r'\b([A-Z]{2,}(?:\s+[A-Z]+)*)\b',  # UPPERCASE acronyms
        r'\b(\w+\s+\w+\s+\w+)\s+(?:algorithm|framework|protocol|architecture|methodology|paradigm)\b', # Multi-word technical concepts
        r'\b(\w+)(?:-based|-oriented|-driven|-specific|-level)\b',  # Technical adjectives
    ]
    
    # Also look for explicit mentions of terms to search
    search_patterns = [
        r"search for (?:information about |details on |explanation of |more about |definition of )?([\w\s\-]+)",
        r"need to explain (?:the )?(?:term |concept |topic )?([\w\s\-]+)",
        r"user might not understand (?:the )?(?:term |concept |topic )?([\w\s\-]+)",
        r"technical term(?:s)? (?:like |such as |including )?([\w\s\-]+)",
    ]
    
    terms = []
    
    # First, look for technical patterns in both thinking and question
    for text in [thinking, question]:
        for pattern in technical_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                term = match.group(1).strip()
                if len(term) > 3 and term.lower() not in [t.lower() for t in terms]:
                    terms.append(term)
    
    # Then check for explicit mentions in thinking
    for pattern in search_patterns:
        matches = re.finditer(pattern, thinking, re.IGNORECASE)
        for match in matches:
            term = match.group(1).strip()
            if len(term) > 3 and term.lower() not in [t.lower() for t in terms]:
                terms.append(term)
    
    # If still no terms found, extract key nouns from question
    if not terms:
        # Focus on extracting technical-sounding noun phrases
        question_terms = re.findall(r'\b([A-Z][a-z]+(?:\s+[a-z]+){0,2})\b|\b([a-z]+(?:\s+[a-z]+){0,2})\b', question)
        question_terms = [t[0] or t[1] for t in question_terms if len(t[0] or t[1]) > 3]
        terms = question_terms[:3]  # Limit to top 3 terms
    
    # Prioritize terms that appear to be more technical
    prioritized_terms = []
    for term in terms:
        # Higher priority for terms with special characters, mixed case, or technical suffixes
        if (re.search(r'[-_]', term) or 
            (re.search(r'[A-Z]', term) and re.search(r'[a-z]', term)) or
            re.search(r'(?:tion|ology|ics|ware|ity|ism|ance|ment)$', term.lower())):
            prioritized_terms.insert(0, term)
        else:
            prioritized_terms.append(term)
    
    return prioritized_terms[:3]  # Limit to top 3 terms

def extract_visualization_topics(thinking: str, question: str) -> List[Dict[str, str]]:
    """Extract topics and styles for visualization from the thinking process."""
    # Look for explicit mentions of things to visualize
    viz_patterns = [
        r"visualize (?:the )?([\w\s\-]+)(?:\s+as a (\w+))?",
        r"create a (?:(\w+) )?(?:diagram|chart|visualization) (?:of |for |showing )?([\w\s\-]+)",
        r"diagram (?:showing |illustrating |of )?([\w\s\-]+)",
        r"flowchart (?:showing |illustrating |of )?([\w\s\-]+)",
    ]
    
    topics = []
    for pattern in viz_patterns:
        matches = re.finditer(pattern, thinking, re.IGNORECASE)
        for match in matches:
            # Check if groups are in expected order
            if len(match.groups()) >= 2:
                if match.group(2):  # Style is second group in some patterns
                    topic, style = match.group(1).strip(), match.group(2).strip()
                else:  # Style is first group in some patterns
                    style, topic = match.group(1).strip(), match.group(2).strip()
                
                # Normalize style
                if style:
                    style = style.lower()
                    if style not in ["diagram", "flowchart", "architecture", "process", "concept"]:
                        style = "diagram"
                else:
                    style = "diagram"
                
                if topic and len(topic) > 3:
                    topics.append({"topic": topic, "style": style})
    

def use_web_search(state: AgentState) -> AgentState:
    """Use web search to get explanations of technical terms."""
    search_terms = extract_search_terms("\n".join(state.thought_process), state.question)
    
    if not search_terms:
        # No terms to search, skip to next step
        return state
    
    logger.info(f"Searching for terms: {search_terms}")
    
    # Store search results for each term
    for term in search_terms:
        try:
            # Try to use the web search tool
            result = web_search_tool(term)
            
            # Check if result is meaningful (not just generic placeholder)
            if (result and 
                not ("refers to a concept in technical documentation" in result) and
                not ("typically describes a process or component" in result)):
                state.search_results[term] = result
            else:
                # Fallback for empty or generic results
                fallback_result = create_fallback_definition(term, state.context)
                state.search_results[term] = fallback_result
                
            time.sleep(1)  # Avoid rate limiting
        except Exception as e:
            logger.exception(f"Error searching for {term}: {e}")
            # Create a fallback definition from context
            fallback_result = create_fallback_definition(term, state.context)
            state.search_results[term] = fallback_result
    
    return state

def create_fallback_definition(term: str, context: List[Dict[str, Any]]) -> str:
    """Create a fallback definition for a term based on context when web search fails."""
    # Look for sentences mentioning the term in the context
    term_lower = term.lower()
    relevant_sentences = []
    
    for chunk in context:
        content = chunk.get("content", "")
        if not content:
            continue
            
        # Split into sentences and look for the term
        sentences = re.split(r'(?<=[.!?])\s+', content)
        for sentence in sentences:
            if term_lower in sentence.lower():
                relevant_sentences.append(sentence.strip())
    
    if relevant_sentences:
        # Construct a definition from relevant context sentences
        definition = f"Based on the document context: {' '.join(relevant_sentences[:3])}"
    else:
        # Create a generic but useful definition based on term characteristics
        if re.search(r'[-_]', term):
            definition = f"{term} appears to be a technical term or identifier mentioned in the document."
        elif re.match(r'^[A-Z]+$', term):
            definition = f"{term} is an acronym mentioned in the document."
        elif re.search(r'(?:tion|ology|ics|ity)$', term.lower()):
            definition = f"{term} refers to a process or methodology mentioned in the document."
        else:
            definition = f"{term} is a term mentioned in the document context."
    
    return definition


def generate_final_answer(state: AgentState) -> AgentState:
    """Generate the final answer using search results and visualizations."""
    # Extract components
    question = state.question
    context = state.context
    search_results = state.search_results
    generated_images = state.generated_images
    formatted_context = format_context_for_llm(context)
    
    # Format search results
    search_results_text = ""
    if search_results:
        search_results_text += "WEB SEARCH RESULTS:\n"
        for term, result in search_results.items():
            search_results_text += f"- Term: {term}\n  Results: {result}\n\n"
    
    # Format image generation results
    image_results_text = ""
    if generated_images:
        image_results_text += "GENERATED VISUALIZATIONS:\n"
        for img in generated_images:
            image_results_text += f"- Topic: {img['topic']} (Style: {img['style']})\n"
            if 'result' in img:
                image_results_text += f"  Result: {img['result']}\n"
            if 'error' in img:
                image_results_text += f"  Error: {img['error']}\n"
    
    # Create a prompt for generating the final answer
    prompt = f"""You are an AI assistant helping an intermediate-level user understand complex document information.
Your task is to generate a clear, educational answer based on the following information.

USER QUESTION: {question}

DOCUMENT CONTEXT:
{formatted_context}

{search_results_text}

{image_results_text}

Generate a comprehensive answer that:
1. Explains concepts clearly for an intermediate user who may not be familiar with all technical terms
2. Cites specific information from the document (use page numbers in parentheses)
3. Includes explanations of technical terms using the web search results
4. References any visualizations that were generated
5. Uses a friendly, educational tone appropriate for someone learning about this topic
6. Organizes the information with clear headings and structure

YOUR ANSWER:
"""

    # Get response from Gemini
    try:
        if not GEMINI_INITIALIZED:
            # Fallback if Gemini isn't initialized
            fallback_answer = f"I couldn't generate a detailed answer because the Gemini API is not configured. Please set your API key in the configuration."
            state.answer = fallback_answer
            state.final_response = {
                "answer": fallback_answer,
                "search_results": search_results,
                "visualizations": generated_images,
            }
            state.done = True
            return state
        
        # Add a more direct answer based on context in case the API fails
        fallback_answer = "Based on the document, "
        if context and len(context) > 0:
            for chunk in context[:3]:  # Use first 3 chunks
                if chunk.get("type") == "text" and chunk.get("content"):
                    fallback_answer += chunk.get("content")[:200] + "... "
        else:
            fallback_answer += "I couldn't find enough information to answer your question."
            
        response = _GEMINI.generate_content(
            prompt,
            generation_config={"temperature": 0.2, "max_output_tokens": 8000}
        )
        
        # Check if response is None or doesn't have text attribute
        if response is None or not hasattr(response, 'text') or response.text is None:
            logger.warning("Received empty response from Gemini API")
            state.answer = fallback_answer
            state.final_response = {
                "answer": fallback_answer,
                "search_results": search_results,
                "visualizations": generated_images,
            }
            state.done = True
            return state
            
        answer = response.text.strip()
        
        # Format the final response
        final_response = {
            "answer": answer,
            "search_results": search_results,
            "visualizations": generated_images,
        }
        
        state.answer = answer
        state.final_response = final_response
        state.done = True
        
    except Exception as e:
        logger.exception(f"Error generating final answer: {e}")
        state.answer = f"Error generating answer: {str(e)}"
        state.final_response = {"error": str(e)}
        state.done = True
    
    return state

def should_use_web_search(state: AgentState) -> str:
    """Decide whether to use web search tool."""
    if "web_search" in state.tools_used and "final_answer" not in state.tools_used:
        return "web_search"
    return "generate_answer"


def should_end(state: AgentState) -> bool:
    """Decide whether to end the agent's execution."""
    return state.done

# Create the agent graph
def create_agent_graph() -> StateGraph:
    """Create the LangGraph for the agent."""
    # Create a new graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("plan", plan_step)
    workflow.add_node("web_search", use_web_search)
    workflow.add_node("generate_answer", generate_final_answer)
    
    # Add edges without using START
    # Add conditional entry point - this replaces the START edge
    workflow.set_entry_point("plan")
    
    workflow.add_edge("plan", "web_search")
    workflow.add_edge("web_search", "generate_answer")
    workflow.add_edge("generate_answer", END)
    
    # Compile the graph
    return workflow.compile()

# Agent executor function
def run_agent(question: str, context: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Run the agent to process a question and context.
    
    Args:
        question: The user's question
        context: List of context chunks from the document
        
    Returns:
        The final response with answer and any visualizations
    """
    # Create the agent graph
    agent_graph = create_agent_graph()
    
    # Set up initial state
    initial_state = AgentState(
        question=question,
        context=context,
    )
    
    # Execute the graph
    try:
        result = agent_graph.invoke(initial_state)
        
        # Extract values directly from the state object
        return {
            "answer": result.get("answer", "No answer was generated."),
            "search_results": result.get("search_results", {}),
            "visualizations": result.get("generated_images", [])
        }
    except Exception as e:
        logger.exception(f"Error running agent: {e}")
        return {
            "error": str(e),
            "answer": f"An error occurred while processing your question: {str(e)}"
        }